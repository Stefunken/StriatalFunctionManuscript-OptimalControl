{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from casadi import *\n",
    "from casadi.tools import *\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import pickle\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcions for finding the optimal trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(x, k, mu, amp):\n",
    "    \"\"\"Generate the spatial cost (approximation of the Heaviside function)\n",
    "    Args:\n",
    "        x: scalar, list or array \n",
    "        k: scalar, steepness of the spatial penalty function \n",
    "        mu: scalar, beam location\n",
    "        amp: scalar, height of the spatial penalty function\n",
    "    Returns:\n",
    "        p: scalar, list or array, value of the spatial cost for x \n",
    "    \"\"\"  \n",
    "    return(amp/(1+np.exp(1+k*(x-mu))))\n",
    "\n",
    "def optimal_trajectory(cost, a, b, xb, xi, xf, tf, vtapis, tau_res, mass, ampxpenalty, kxpenalty, nk):\n",
    "    \"\"\"Compute the optimal trajectory\n",
    "    Args:\n",
    "        cost: string, cost type (defines the effort and spacial costs)  \n",
    "        a: scalar, effort sensitivity \n",
    "        b: scalar, spacial sensitivity\n",
    "        xb: scalar, beam location\n",
    "        xi: scalar, initial position\n",
    "        xf: scalar, final position\n",
    "        tf: scalar, final time (entrance time)\n",
    "        vtapis: scalar, treadmill speed\n",
    "        tau_res: scalar, resistive force, tau\n",
    "        mass: scalar, rat's weight (mass)\n",
    "        ampxpenalty: scalar, height of the spatial penalty function\n",
    "        kxpenalty: scalar, steepness of the spatial penalty function \n",
    "        nk: scalar, number of collocation points\n",
    "    Returns:\n",
    "        (x0_opt,x1_opt,tgrid,u_opt,tgrid_u,float(res[\"f\"])): lists; optimal positions, optimal speeds\n",
    "        time for postion and speed), optimal control, time for optimal control, final total cost. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Ltread=0.9\n",
    "    mu=0.1    # Control discretization\n",
    "    kT=mu/1\n",
    "    \n",
    "    # Declare variables\n",
    "    t  = SX.sym(\"t\")    # time\n",
    "    u  = SX.sym(\"u\")    # control\n",
    "\n",
    "    states = struct_symSX([\n",
    "            entry('x',shape=2),    #  states\n",
    "            entry('L')             #  helper state: Langrange integrand\n",
    "         ])\n",
    "\n",
    "    # Create a structure for the right hand side\n",
    "    rhs = struct_SX(states)\n",
    "    x = states['x']\n",
    "    rhs[\"x\"] = vertcat(x[1],u)    \n",
    "    rhs[\"x\"] = vertcat(x[1],u - fabs(x[1]-vtapis)/tau_res)\n",
    "        \n",
    "    \n",
    "    if cost=='speed_quadratic':\n",
    "        \n",
    "        rhs[\"L\"] = a*mass*(x[1]-vtapis)**2 + b*(x[0]-Ltread)**2\n",
    "    \n",
    "    elif cost=='force_quadratic':   \n",
    "        rhs[\"L\"] = a*(mass*u)**2 + b*(x[0]-Ltread)**2  \n",
    "\n",
    "    elif cost=='speed_heaviside':\n",
    "        \n",
    "        rhs[\"L\"] = a*mass*(x[1]-vtapis)**2 + b*penalty(x=x[0],k=kxpenalty,mu=xb,amp=ampxpenalty)\n",
    "    \n",
    "    elif cost=='force_heaviside':   \n",
    "        rhs[\"L\"] = a*(mass*u)**2 + b*penalty(x=x[0],k=kxpenalty,mu=xb,amp=ampxpenalty)\n",
    "\n",
    "    # ODE right hand side function\n",
    "    f = Function('f', [t,states,u],[rhs])\n",
    "\n",
    "    # Objective function (meyer term)\n",
    "    m = Function('m', [t,states,u],[states[\"L\"]])\n",
    "\n",
    "    # Control bounds\n",
    "    u_min = -7.5\n",
    "    u_max = 7.5\n",
    "    u_init = 0.0\n",
    "\n",
    "    u_lb = np.array([u_min])\n",
    "    u_ub = np.array([u_max])\n",
    "    u_init = np.array([u_init])\n",
    "\n",
    "    # State bounds and initial guess\n",
    "    x_min =  [0.0,   vtapis-0.7, -inf]\n",
    "    x_max =  [Ltread,vtapis,  inf]\n",
    "    xi_min = [xi,  vtapis-0.7,  0.0]\n",
    "    xi_max = [xi,  vtapis,  inf]\n",
    "    xf_min = [xf,  vtapis-0.7, -inf]\n",
    "    xf_max = [xf,  vtapis,  inf]\n",
    "    x_init = [ 0.0,  0.0,  0.0]\n",
    "\n",
    "    # Dimensions\n",
    "    nx = 3\n",
    "    nu = 1\n",
    "\n",
    "    # Choose collocation points\n",
    "    tau_root = [0] + collocation_points(3,\"radau\")\n",
    "\n",
    "    # Degree of interpolating polynomial\n",
    "    d = len(tau_root)-1\n",
    "\n",
    "    # Size of the finite elements\n",
    "    h = tf/nk\n",
    "\n",
    "    # Coefficients of the collocation equation\n",
    "    C = np.zeros((d+1,d+1))\n",
    "\n",
    "    # Coefficients of the continuity equation\n",
    "    D = np.zeros(d+1)\n",
    "\n",
    "    # Dimensionless time inside one control interval\n",
    "    tau = SX.sym(\"tau\")\n",
    "\n",
    "    # All collocation time points\n",
    "    T = np.zeros((nk,d+1))\n",
    "    for k in range(nk):\n",
    "        for j in range(d+1):\n",
    "            T[k,j] = h*(k + tau_root[j])\n",
    "\n",
    "    # For all collocation points\n",
    "    for j in range(d+1):\n",
    "    # Construct Lagrange polynomials to get the polynomial basis at the collocation point\n",
    "        L = 1\n",
    "        for r in range(d+1):\n",
    "            if r != j:\n",
    "                L *= (tau-tau_root[r])/(tau_root[j]-tau_root[r])\n",
    "\n",
    "        # Evaluate the polynomial at the final time to get the coefficients of the continuity equation\n",
    "        lfcn = Function('lfcn', [tau],[L])\n",
    "        D[j] = lfcn(1.0)\n",
    "\n",
    "        # Evaluate the time derivative of the polynomial at all collocation points to get the coefficients of the continuity equation\n",
    "        tfcn = Function('tfcn', [tau],[tangent(L,tau)])\n",
    "        for r in range(d+1):\n",
    "            C[j,r] = tfcn(tau_root[r])\n",
    "\n",
    "    # Structure holding NLP variables\n",
    "    V = struct_symMX([\n",
    "      (\n",
    "       entry(\"X\",repeat=[nk+1,d+1],struct=states),\n",
    "       entry(\"U\",repeat=[nk],shape=nu)\n",
    "      )\n",
    "    ])\n",
    "\n",
    "    vars_lb   = V()\n",
    "    vars_ub   = V()\n",
    "    vars_init = V()\n",
    "\n",
    "    # Set states and its bounds\n",
    "    vars_init[\"X\",:,:] = repeated(repeated(x_init))\n",
    "    vars_lb[\"X\",:,:]   = repeated(repeated(x_min))\n",
    "    vars_ub[\"X\",:,:]   = repeated(repeated(x_max))\n",
    "\n",
    "    # Set controls and its bounds\n",
    "    vars_init[\"U\",:] = repeated(u_init)\n",
    "    vars_lb[\"U\",:]   = repeated(u_min)\n",
    "    vars_ub[\"U\",:]   = repeated(u_max)\n",
    "\n",
    "    # State at initial time\n",
    "    vars_lb[\"X\",0,0] = xi_min\n",
    "    vars_ub[\"X\",0,0] = xi_max\n",
    "\n",
    "    # State at end time\n",
    "    vars_lb[\"X\",-1,0] = xf_min\n",
    "    vars_ub[\"X\",-1,0] = xf_max\n",
    "\n",
    "    # Constraint function for the NLP\n",
    "    g = []\n",
    "    lbg = []\n",
    "    ubg = []\n",
    "\n",
    "    # For all finite elements\n",
    "    for k in range(nk):\n",
    "\n",
    "        # For all collocation points\n",
    "        for j in range(1,d+1):\n",
    "\n",
    "        # Get an expression for the state derivative at the collocation point\n",
    "            xp_jk = 0\n",
    "            for r in range (d+1):\n",
    "                xp_jk += C[r,j]*V[\"X\",k,r]\n",
    "\n",
    "            # Add collocation equations to the NLP\n",
    "            fk = f(T[k][j], V[\"X\",k,j], V[\"U\",k])\n",
    "            g.append(h*fk - xp_jk)\n",
    "            lbg.append(np.zeros(nx)) # equality constraints\n",
    "            ubg.append(np.zeros(nx)) # equality constraints\n",
    "\n",
    "        # Get an expression for the state at the end of the finite element\n",
    "        xf_k = 0\n",
    "        for r in range(d+1):\n",
    "            xf_k += D[r]*V[\"X\",k,r]\n",
    "\n",
    "        # Add continuity equation to NLP\n",
    "        g.append(V[\"X\",k+1,0] - xf_k)\n",
    "        lbg.append(np.zeros(nx))\n",
    "        ubg.append(np.zeros(nx))\n",
    "\n",
    "    # Concatenate constraints\n",
    "    g = vertcat(*g)\n",
    "\n",
    "    # Objective function\n",
    "    f = m(T[nk-1][d],V[\"X\",nk,0],V[\"U\",nk-1])\n",
    "\n",
    "    # NLP\n",
    "    nlp = {'x':V, 'f':f, 'g':g}\n",
    "\n",
    "    ## ----\n",
    "    ## SOLVE THE NLP\n",
    "    ## ----\n",
    "\n",
    "    # Set options\n",
    "    opts = {}\n",
    "    opts[\"expand\"] = True\n",
    "    #opts[\"ipopt.max_iter\"] = 4\n",
    "\n",
    "    # Allocate an NLP solver\n",
    "    solver = nlpsol(\"solver\", \"ipopt\", nlp, opts)\n",
    "    arg = {}\n",
    "\n",
    "    # Initial condition\n",
    "    arg[\"x0\"] = vars_init\n",
    "\n",
    "    # Bounds on x\n",
    "    arg[\"lbx\"] = vars_lb\n",
    "    arg[\"ubx\"] = vars_ub\n",
    "\n",
    "    # Bounds on g\n",
    "    arg[\"lbg\"] = np.concatenate(lbg)\n",
    "    arg[\"ubg\"] = np.concatenate(ubg)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = solver(**arg)\n",
    "\n",
    "    # Print the optimal cost\n",
    "    print(\"optimal cost: \", float(res[\"f\"]))\n",
    "\n",
    "    # Retrieve the solution\n",
    "    opt = V(res[\"x\"])\n",
    "\n",
    "    # Get values at the beginning of each finite element\n",
    "    x0_opt = opt[\"X\",:,0,\"x\",0]\n",
    "    x1_opt = opt[\"X\",:,0,\"x\",1]\n",
    "    x2_opt = opt[\"X\",:,0,\"L\"]\n",
    "\n",
    "    u_opt = opt[\"U\",:,0]\n",
    "\n",
    "    tgrid = np.linspace(0,tf,nk+1)\n",
    "    tgrid_u = np.linspace(0,tf,nk)\n",
    "    \n",
    "    return x0_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './Data_for_fit/Before/'\n",
    "file_to_open = data_folder + 'clean_max_pos_traj.pickle'\n",
    "with open(file_to_open, 'rb') as handle:\n",
    "    trajectories_before = pickle.load(handle)    \n",
    "file_to_open = data_folder + 'clean_ET_max_pos.pickle'\n",
    "with open(file_to_open, 'rb') as handle:\n",
    "    tf_before = pickle.load(handle)  \n",
    "    \n",
    "data_folder = './Data_for_fit/Final/'\n",
    "file_to_open = data_folder + 'clean_max_pos_traj.pickle'\n",
    "with open(file_to_open, 'rb') as handle:\n",
    "    trajectories_final = pickle.load(handle)\n",
    "file_to_open = data_folder + 'clean_ET_max_pos.pickle'\n",
    "with open(file_to_open, 'rb') as handle:\n",
    "    tf_final = pickle.load(handle)    \n",
    "    \n",
    "file_to_open = data_folder + '_lesion_size_.p'   \n",
    "with open(file_to_open, 'rb') as handle:\n",
    "    lesion_size_final = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './Data_for_fit/'\n",
    "file_to_open = data_folder + 'AnimalList.txt'\n",
    "\n",
    "selected_rats = []   \n",
    "crimefile = open(file_to_open, 'r')\n",
    "reader = csv.reader(crimefile)\n",
    "rats_list = [row for row in reader]\n",
    "for i_rat, aux in enumerate(rats_list):\n",
    "    selected_rats.append(rats_list[i_rat][0][:])\n",
    "#selected_rats[-1] = 'Rat221' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.04\n",
    "shift_time = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = 'PickleResults/Fit'\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampxpenalty = 10\n",
    "kxpenalty = 1\n",
    "xb = 0.1\n",
    "vtapis = 0.1\n",
    "tau_res = 1.8\n",
    "mass = 1\n",
    "shift_time = 1 # s \n",
    "b = 1\n",
    "bounds = optimize.Bounds(0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the trajectory corresponding to the median max position (for each animal and for each session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Parameter fit- Before Lesion\n",
    "ig_before = 1\n",
    "a_fit_before_dict = dict()\n",
    "xk_fit_before_dict = dict()\n",
    "\n",
    "for rat in selected_rats:\n",
    "#for rat in [selected_rats[2]]:\n",
    "    \n",
    "    a_fit_list = []\n",
    "    xk_fit_list = []\n",
    "    \n",
    "    for i_sess in range(len(trajectories_before[rat])):\n",
    "\n",
    "        real_trajectory = trajectories_before[rat][i_sess][int(shift_time/dt):]*0.01\n",
    "        xi = real_trajectory[0]\n",
    "        xf = real_trajectory[-1]\n",
    "        tf = tf_before[rat][i_sess]-shift_time\n",
    "        nk = len(real_trajectory)-1\n",
    "\n",
    "        def E(a,cost='speed_heaviside',b=b,\n",
    "                         xb=xb,xi=xi,xf=xf,tf=tf,\n",
    "                         vtapis=vtapis,tau_res=tau_res, mass=mass,\n",
    "                         ampxpenalty=ampxpenalty,kxpenalty=kxpenalty,nk=nk, \n",
    "                         real_trajectory=real_trajectory):\n",
    "\n",
    "            xk = optimal_trajectory(cost='speed_heaviside',a=a,b=b,\n",
    "                                    xb=xb,xi=xi,xf=xf,tf=tf,\n",
    "                                    vtapis=vtapis,tau_res=tau_res, mass=mass,\n",
    "                                    ampxpenalty=ampxpenalty,kxpenalty=kxpenalty,nk=nk)    \n",
    "\n",
    "            #return np.abs((np.max(xk)-np.max(real_trajectory)))\n",
    "            return np.sum((xk-real_trajectory)**2) \n",
    "        \n",
    "        res = optimize.minimize(E, x0=np.array([ig_before]), method='trust-constr', \n",
    "                                bounds=bounds, options={'xtol': 1e-1, 'disp': True})\n",
    "        \n",
    "        a_fit = res.x[0]\n",
    "        xk_fit = optimal_trajectory(cost='speed_heaviside',a=a_fit,b=b,\n",
    "                                xb=xb,xi=xi,xf=xf,tf=tf,\n",
    "                                vtapis=vtapis,tau_res=tau_res, mass=mass,\n",
    "                                ampxpenalty=ampxpenalty,kxpenalty=kxpenalty,nk=nk)\n",
    "        \n",
    "        a_fit_list.append(a_fit)\n",
    "        xk_fit_list.append(xk_fit)\n",
    "    \n",
    "    a_fit_before_dict[rat] = a_fit_list\n",
    "    xk_fit_before_dict[rat] = xk_fit_list\n",
    "    \n",
    "with open(results_folder + '/xk_fit_bounded_beforeXX.pickle', 'wb') as handle:\n",
    "    pickle.dump(xk_fit_before_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "\n",
    "with open(results_folder + '/a_fit_bounded_beforeXX.pickle', 'wb') as handle:\n",
    "    pickle.dump(a_fit_before_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "\n",
    "###########################################################\n",
    "# Parameter fit- After Lesion\n",
    "ig_after = 5\n",
    "a_fit_final_dict = dict()\n",
    "xk_fit_final_dict = dict()\n",
    "\n",
    "for rat in selected_rats:\n",
    "#for rat in [selected_rats[2]]:\n",
    "    a_fit_list = []\n",
    "    xk_fit_list = []\n",
    "    \n",
    "    for i_sess in range(len(trajectories_final[rat])):\n",
    "\n",
    "        real_trajectory = trajectories_final[rat][i_sess][int(shift_time/dt):]*0.01\n",
    "        xi = real_trajectory[0]\n",
    "        xf = real_trajectory[-1]\n",
    "        tf = tf_final[rat][i_sess]-shift_time\n",
    "        nk = len(real_trajectory)-1\n",
    "        \n",
    "        def E(a,cost='speed_heaviside',b=b,\n",
    "                         xb=xb,xi=xi,xf=xf,tf=tf,\n",
    "                         vtapis=vtapis,tau_res=tau_res, mass=mass, \n",
    "                         ampxpenalty=ampxpenalty,kxpenalty=kxpenalty,nk=nk, \n",
    "                         real_trajectory=real_trajectory):\n",
    "\n",
    "            xk = optimal_trajectory(cost='speed_heaviside',a=a,b=b,\n",
    "                                    xb=xb,xi=xi,xf=xf,tf=tf,\n",
    "                                    vtapis=vtapis,tau_res=tau_res, mass=mass, \n",
    "                                    ampxpenalty=ampxpenalty,kxpenalty=kxpenalty,nk=nk)    \n",
    "\n",
    "            #return np.abs((np.max(xk)-np.max(real_trajectory)))\n",
    "            return np.sum((xk-real_trajectory)**2) \n",
    "        \n",
    "        #res = optimize.minimize(E, x0=np.array([ig_after]), method='nelder-mead' ,\n",
    "        #                        options={'xatol': 1e-1, 'disp': True}) \n",
    "        res = optimize.minimize(E, x0=np.array([ig_after]), method='trust-constr', \n",
    "                                bounds=bounds, options={'xtol': 1e-1, 'disp': True})        \n",
    "        a_fit = res.x[0]\n",
    "        xk_fit = optimal_trajectory(cost='speed_heaviside',a=a_fit,b=b,\n",
    "                                xb=xb,xi=xi,xf=xf,tf=tf,\n",
    "                                vtapis=vtapis,tau_res=tau_res, mass=mass,\n",
    "                                ampxpenalty=ampxpenalty,kxpenalty=kxpenalty,nk=nk)\n",
    "        \n",
    "        a_fit_list.append(a_fit)\n",
    "        xk_fit_list.append(xk_fit)\n",
    "    \n",
    "    a_fit_final_dict[rat] = a_fit_list\n",
    "    xk_fit_final_dict[rat] = xk_fit_list\n",
    "    \n",
    "with open(results_folder + '/xk_fit_bounded_finalXX.pickle', 'wb') as handle:\n",
    "    pickle.dump(xk_fit_final_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "\n",
    "with open(results_folder + '/a_fit_bounded_finalXX.pickle', 'wb') as handle:\n",
    "    pickle.dump(a_fit_final_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute delta alpha median and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_a_median_bounded_dict = {rat: np.median(np.array(a_fit_final_dict[rat]))-\n",
    "                       np.median(np.array(a_fit_before_dict[rat])) for rat in tuple(selected_rats)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_folder + '/delta_a_boundedXX.pickle', 'wb') as handle:\n",
    "    pickle.dump(delta_a_median_bounded_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
